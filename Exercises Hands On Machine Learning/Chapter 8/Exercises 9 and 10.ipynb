{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "Load the MNIST dataset (introduced in Chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing). Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set. Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Next, evaluate the classifier on the test set. How does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "# ignore warnings because they're annoying\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# set up data\n",
    "X = np.array(mnist.data)\n",
    "y = np.array(mnist.target).astype(int)\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = (1/7)) # have 20k samples in valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 63.44660663604736 seconds ---\n"
     ]
    }
   ],
   "source": [
    "rdm_clf = RandomForestClassifier(random_state=42)\n",
    "# time the training time of our classifier\n",
    "import time\n",
    "start_time = time.time()\n",
    "rdm_clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of our classifier\n",
    "y_pred = rdm_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 124.11359477043152 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# using PCA analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95) # capture 95% of the variance in the dataset\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "# create new random forest classifier\n",
    "rdm_clf2 = RandomForestClassifier(random_state = 42)\n",
    "start_time = time.time()\n",
    "rdm_clf2.fit(X_reduced, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493\n"
     ]
    }
   ],
   "source": [
    "# new model only understands 154 features\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "# test accuracy of our second classifier\n",
    "y_pred = rdm_clf2.predict(X_test_reduced)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results show that our model performs worse when using PCA and takes longer to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10\n",
    "Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image’s target class. Alternatively, you can replace each dot in the scatterplot with the corresponding instance’s class (a digit from 0 to 9), or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "manifold = tsne.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
