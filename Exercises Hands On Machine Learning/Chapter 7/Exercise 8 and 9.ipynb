{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import warnings\n",
    "# ignore warnings because they're annoying\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# set up data\n",
    "X = np.array(mnist.data)\n",
    "y = np.array(mnist.target).astype(int)\n",
    "\n",
    "# split the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = (2/7)) # have 20k samples in valid\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = .5) # split 20k into 10k for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the SVC\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\", SVC(gamma = \"auto\", random_state = 42))\n",
    "])\n",
    "# Random Forest doesn't care for standardized values\n",
    "# Set everything to default because no point in playing with hyperparameters just yet\n",
    "rdm_for = RandomForestClassifier(random_state = 42)\n",
    "# Now for Extra Trees Classifier\n",
    "extra = ExtraTreesClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all the models\n",
    "svm_clf.fit(X_train, y_train)\n",
    "rdm_for.fit(X_train, y_train)\n",
    "extra.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:  0.9655\n",
      "Random Forrest Accuracy:  0.9672\n",
      "Extra Trees Accuracy:  0.9711\n"
     ]
    }
   ],
   "source": [
    "# make predictions for all values\n",
    "svm_pred = svm_clf.predict(X_valid)\n",
    "rdm_pred = rdm_for.predict(X_valid)\n",
    "extra_pred = extra.predict(X_valid)\n",
    "\n",
    "print(\"SVM Accuracy: \", accuracy_score(svm_pred, y_valid))\n",
    "print(\"Random Forrest Accuracy: \", accuracy_score(rdm_pred, y_valid))\n",
    "print(\"Extra Trees Accuracy: \", accuracy_score(extra_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svm',\n",
       "                              Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                              ('svc',\n",
       "                                               SVC(gamma='auto',\n",
       "                                                   random_state=42))])),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('extra', ExtraTreesClassifier(random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use a simple voting classifier ensemble for our models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('svm', svm_clf),('rf', rdm_for),('extra',extra)],\n",
    "    voting = 'hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy:  0.9728\n"
     ]
    }
   ],
   "source": [
    "voting_pred = voting_clf.predict(X_valid)\n",
    "\n",
    "print(\"Ensemble Accuracy: \", accuracy_score(voting_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing how it would perform using the test set data\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the accuracy score alone, my ensemble performs better than all 3 of the classifiers working my themselves. This however should be taken with a grain of salt as we need to see our confusion matrix, ROC-AUC curves, and classification report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’s class. Train a classifier on this new training set. Congratulations, you have just trained a blender, and together with the classifiers it forms a stacking ensemble! Now evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble’s predictions. How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an estimators list object\n",
    "estimators = [svm_clf, rdm_for, extra]\n",
    "# make a 10,000 x 3 empty matrix\n",
    "X_val_predictions = np.empty((len(X_valid), len(estimators)), dtype=np.float32)\n",
    "\n",
    "# for loop to make things easier and faster :)\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a blender using a random forest classifier\n",
    "rnd_forest_blender = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the predicted accuracy score of our blender model\n",
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:,index] = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble Accuracy:  0.973\n"
     ]
    }
   ],
   "source": [
    "# have stacked ensemble predict X_test\n",
    "y_pred = rnd_forest_blender.predict(X_test_predictions)\n",
    "\n",
    "# Accuracy score of stacked ensemble on X_test\n",
    "print(\"Stacked Ensemble Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
