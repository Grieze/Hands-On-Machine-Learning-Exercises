{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "Practice training a deep neural network on the CIFAR10 image dataset:\n",
    "\n",
    "a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation\n",
    "function.\n",
    "\n",
    "b. Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output\n",
    "layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters.\n",
    "\n",
    "c. Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it\n",
    "affect training speed?\n",
    "\n",
    "d. Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features,\n",
    "use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).\n",
    "\n",
    "e. Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.\n",
    "\n",
    "f. Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "\n",
    "# Since we're creating a sequential model and want to keep our code neat and clean I'm going to create a partial object\n",
    "# and add 20 DenseLayers using a for loop to make life easier and faster\n",
    "DenseLayer = partial(keras.layers.Dense,\n",
    "                     activation=\"elu\",\n",
    "                     kernel_initializer=\"he_normal\")\n",
    "# initialize the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32, 32, 3]),])\n",
    "# add 20 hidden layers of 100 neuron Dense layers \n",
    "for _ in range(0,20):\n",
    "    model.add(DenseLayer(100))\n",
    "# add our output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(lr=5e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "import os\n",
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "# create an early stopping callback\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the model is built, let's download our data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 17s 429us/sample - loss: 4.3715 - accuracy: 0.1601 - val_loss: 2.1827 - val_accuracy: 0.1908\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 14s 342us/sample - loss: 2.0893 - accuracy: 0.2342 - val_loss: 2.0220 - val_accuracy: 0.2546\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 14s 361us/sample - loss: 1.9651 - accuracy: 0.2803 - val_loss: 1.9471 - val_accuracy: 0.2951\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 15s 364us/sample - loss: 1.8880 - accuracy: 0.3143 - val_loss: 1.8615 - val_accuracy: 0.3247\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 14s 360us/sample - loss: 1.8287 - accuracy: 0.3356 - val_loss: 1.8118 - val_accuracy: 0.3423\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 14s 351us/sample - loss: 1.7768 - accuracy: 0.3535 - val_loss: 1.7557 - val_accuracy: 0.3631\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.7335 - accuracy: 0.3749 - val_loss: 1.7267 - val_accuracy: 0.3700\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.6922 - accuracy: 0.3871 - val_loss: 1.6736 - val_accuracy: 0.3939\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 14s 350us/sample - loss: 1.6574 - accuracy: 0.4020 - val_loss: 1.6966 - val_accuracy: 0.3867\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.6346 - accuracy: 0.4078 - val_loss: 1.6657 - val_accuracy: 0.3968\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 14s 355us/sample - loss: 1.6082 - accuracy: 0.4153 - val_loss: 1.6604 - val_accuracy: 0.4023\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 14s 354us/sample - loss: 1.5870 - accuracy: 0.4293 - val_loss: 1.6297 - val_accuracy: 0.4177\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 14s 360us/sample - loss: 1.5630 - accuracy: 0.4360 - val_loss: 1.6184 - val_accuracy: 0.4083\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 14s 353us/sample - loss: 1.5470 - accuracy: 0.4401 - val_loss: 1.6258 - val_accuracy: 0.4126\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.5296 - accuracy: 0.4491 - val_loss: 1.6191 - val_accuracy: 0.4220\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.5091 - accuracy: 0.4532 - val_loss: 1.6097 - val_accuracy: 0.4244\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 14s 351us/sample - loss: 1.4982 - accuracy: 0.4593 - val_loss: 1.5852 - val_accuracy: 0.4343\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.4812 - accuracy: 0.4652 - val_loss: 1.5668 - val_accuracy: 0.4383\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.4658 - accuracy: 0.4712 - val_loss: 1.5810 - val_accuracy: 0.4389\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.4549 - accuracy: 0.4757 - val_loss: 1.5851 - val_accuracy: 0.4291\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.4441 - accuracy: 0.4793 - val_loss: 1.5536 - val_accuracy: 0.4458\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 14s 350us/sample - loss: 1.4300 - accuracy: 0.4828 - val_loss: 1.5379 - val_accuracy: 0.4507\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.4190 - accuracy: 0.4895 - val_loss: 1.5697 - val_accuracy: 0.4454\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.4091 - accuracy: 0.4903 - val_loss: 1.6053 - val_accuracy: 0.4302\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.3960 - accuracy: 0.4963 - val_loss: 1.5430 - val_accuracy: 0.4560\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.3849 - accuracy: 0.4985 - val_loss: 1.5614 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.3776 - accuracy: 0.5041 - val_loss: 1.5393 - val_accuracy: 0.4532\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.3687 - accuracy: 0.5062 - val_loss: 1.5394 - val_accuracy: 0.4575\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.3598 - accuracy: 0.5105 - val_loss: 1.6545 - val_accuracy: 0.4199\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.3489 - accuracy: 0.5139 - val_loss: 1.5340 - val_accuracy: 0.4562\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 14s 349us/sample - loss: 1.3365 - accuracy: 0.5175 - val_loss: 1.5544 - val_accuracy: 0.4509\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.3297 - accuracy: 0.5212 - val_loss: 1.5682 - val_accuracy: 0.4491\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.3238 - accuracy: 0.5242 - val_loss: 1.5363 - val_accuracy: 0.4602\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 14s 350us/sample - loss: 1.3125 - accuracy: 0.5293 - val_loss: 1.5320 - val_accuracy: 0.4609\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 14s 351us/sample - loss: 1.3044 - accuracy: 0.5325 - val_loss: 1.5224 - val_accuracy: 0.4654\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.2967 - accuracy: 0.5312 - val_loss: 1.5514 - val_accuracy: 0.4551\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.2841 - accuracy: 0.5393 - val_loss: 1.5670 - val_accuracy: 0.4572\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 14s 347us/sample - loss: 1.2782 - accuracy: 0.5398 - val_loss: 1.5561 - val_accuracy: 0.4628\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.2711 - accuracy: 0.5419 - val_loss: 1.5338 - val_accuracy: 0.4638\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 14s 346us/sample - loss: 1.2640 - accuracy: 0.5442 - val_loss: 1.5334 - val_accuracy: 0.4561\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 14s 345us/sample - loss: 1.2579 - accuracy: 0.5462 - val_loss: 1.5438 - val_accuracy: 0.4608\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 14s 345us/sample - loss: 1.2478 - accuracy: 0.5506 - val_loss: 1.5325 - val_accuracy: 0.4754\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 14s 344us/sample - loss: 1.2405 - accuracy: 0.5527 - val_loss: 1.5500 - val_accuracy: 0.4677\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 14s 345us/sample - loss: 1.2354 - accuracy: 0.5543 - val_loss: 1.5697 - val_accuracy: 0.4550\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 14s 348us/sample - loss: 1.2267 - accuracy: 0.5561 - val_loss: 1.5521 - val_accuracy: 0.4597\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 98us/sample - loss: 1.5224 - accuracy: 0.4654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5223829399108886, 0.4654]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 35s 878us/sample - loss: 1.9428 - accuracy: 0.3000 - val_loss: 1.7137 - val_accuracy: 0.3789\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 23s 583us/sample - loss: 1.7338 - accuracy: 0.3850 - val_loss: 1.6100 - val_accuracy: 0.4244\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 24s 595us/sample - loss: 1.6523 - accuracy: 0.4124 - val_loss: 1.5677 - val_accuracy: 0.4505\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 24s 595us/sample - loss: 1.6033 - accuracy: 0.4315 - val_loss: 1.5255 - val_accuracy: 0.4518\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 24s 596us/sample - loss: 1.5522 - accuracy: 0.4486 - val_loss: 1.5028 - val_accuracy: 0.4660\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 24s 600us/sample - loss: 1.5107 - accuracy: 0.4655 - val_loss: 1.4669 - val_accuracy: 0.4740\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 24s 606us/sample - loss: 1.4755 - accuracy: 0.4744 - val_loss: 1.4442 - val_accuracy: 0.4905\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 24s 602us/sample - loss: 1.4450 - accuracy: 0.4889 - val_loss: 1.4453 - val_accuracy: 0.4905\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.4159 - accuracy: 0.4995 - val_loss: 1.4310 - val_accuracy: 0.4937\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 24s 588us/sample - loss: 1.3928 - accuracy: 0.5102 - val_loss: 1.4454 - val_accuracy: 0.4869\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 24s 592us/sample - loss: 1.3675 - accuracy: 0.5180 - val_loss: 1.4045 - val_accuracy: 0.5069\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.3346 - accuracy: 0.5271 - val_loss: 1.4081 - val_accuracy: 0.5079\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 24s 602us/sample - loss: 1.3137 - accuracy: 0.5369 - val_loss: 1.4056 - val_accuracy: 0.5095\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.2989 - accuracy: 0.5453 - val_loss: 1.3947 - val_accuracy: 0.5131\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 1.2804 - accuracy: 0.5479 - val_loss: 1.4038 - val_accuracy: 0.5126\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 24s 604us/sample - loss: 1.2650 - accuracy: 0.5571 - val_loss: 1.3721 - val_accuracy: 0.5176\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 24s 604us/sample - loss: 1.2479 - accuracy: 0.5620 - val_loss: 1.3932 - val_accuracy: 0.5157\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 24s 592us/sample - loss: 1.2253 - accuracy: 0.5686 - val_loss: 1.3803 - val_accuracy: 0.5260\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 24s 591us/sample - loss: 1.2134 - accuracy: 0.5744 - val_loss: 1.3814 - val_accuracy: 0.5179\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 1.1944 - accuracy: 0.5807 - val_loss: 1.4117 - val_accuracy: 0.5134\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 1.1824 - accuracy: 0.5871 - val_loss: 1.3901 - val_accuracy: 0.5155\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 24s 595us/sample - loss: 1.1657 - accuracy: 0.5902 - val_loss: 1.3935 - val_accuracy: 0.5172\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.1495 - accuracy: 0.5952 - val_loss: 1.3848 - val_accuracy: 0.5257\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 23s 584us/sample - loss: 1.1351 - accuracy: 0.6028 - val_loss: 1.3927 - val_accuracy: 0.5197\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 24s 589us/sample - loss: 1.1252 - accuracy: 0.6067 - val_loss: 1.3713 - val_accuracy: 0.5250\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 23s 586us/sample - loss: 1.1099 - accuracy: 0.6095 - val_loss: 1.3871 - val_accuracy: 0.5189\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 24s 588us/sample - loss: 1.1064 - accuracy: 0.6111 - val_loss: 1.3912 - val_accuracy: 0.5284\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 23s 585us/sample - loss: 1.0860 - accuracy: 0.6203 - val_loss: 1.4057 - val_accuracy: 0.5248\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 23s 586us/sample - loss: 1.0764 - accuracy: 0.6225 - val_loss: 1.4014 - val_accuracy: 0.5267\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 23s 586us/sample - loss: 1.0563 - accuracy: 0.6326 - val_loss: 1.3951 - val_accuracy: 0.5270\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 1.0559 - accuracy: 0.6320 - val_loss: 1.3775 - val_accuracy: 0.5280\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.0438 - accuracy: 0.6369 - val_loss: 1.4105 - val_accuracy: 0.5202\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 24s 591us/sample - loss: 1.0279 - accuracy: 0.6380 - val_loss: 1.4049 - val_accuracy: 0.5232\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 24s 590us/sample - loss: 1.0267 - accuracy: 0.6408 - val_loss: 1.4401 - val_accuracy: 0.5184\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 24s 591us/sample - loss: 1.0130 - accuracy: 0.6489 - val_loss: 1.4059 - val_accuracy: 0.5277\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 1.0068 - accuracy: 0.6512 - val_loss: 1.4474 - val_accuracy: 0.5158\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 24s 589us/sample - loss: 0.9931 - accuracy: 0.6529 - val_loss: 1.4456 - val_accuracy: 0.5186\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 0.9836 - accuracy: 0.6556 - val_loss: 1.4314 - val_accuracy: 0.5192\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 24s 603us/sample - loss: 0.9709 - accuracy: 0.6592 - val_loss: 1.4218 - val_accuracy: 0.5224\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 24s 602us/sample - loss: 0.9687 - accuracy: 0.6618 - val_loss: 1.4353 - val_accuracy: 0.5156\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 24s 593us/sample - loss: 0.9507 - accuracy: 0.6676 - val_loss: 1.4352 - val_accuracy: 0.5237\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 0.9428 - accuracy: 0.6706 - val_loss: 1.4802 - val_accuracy: 0.5161\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 0.9493 - accuracy: 0.6695 - val_loss: 1.4829 - val_accuracy: 0.5113\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 0.9275 - accuracy: 0.6765 - val_loss: 1.4387 - val_accuracy: 0.5227\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 0.9258 - accuracy: 0.6783 - val_loss: 1.4871 - val_accuracy: 0.5123\n",
      "10000/10000 [==============================] - 2s 177us/sample - loss: 1.3713 - accuracy: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3712681060791017, 0.525]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseLayer = partial(keras.layers.Dense,\n",
    "                     activation=\"elu\",\n",
    "                     kernel_initializer=\"he_normal\")\n",
    "# initialize the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "])\n",
    "\n",
    "# add 20 hidden layers of 100 neuron Dense layers \n",
    "for _ in range(0,20):\n",
    "    model.add(DenseLayer(100))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "# add our output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(lr=5e-4),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "# test the model\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "])\n",
    "\n",
    "# add 20 hidden layers of 100 neuron Dense layers \n",
    "for _ in range(0,20):\n",
    "    model.add(keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "# add our output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(lr=7e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 495us/sample - loss: 1.8818 - accuracy: 0.3294 - val_loss: 1.7372 - val_accuracy: 0.3807\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 1.6861 - accuracy: 0.3986 - val_loss: 1.6407 - val_accuracy: 0.4107\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 16s 398us/sample - loss: 1.5886 - accuracy: 0.4327 - val_loss: 1.5976 - val_accuracy: 0.4305\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 16s 389us/sample - loss: 1.5304 - accuracy: 0.4547 - val_loss: 1.5554 - val_accuracy: 0.4496\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 15s 385us/sample - loss: 1.4782 - accuracy: 0.4756 - val_loss: 1.5455 - val_accuracy: 0.4518\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 16s 392us/sample - loss: 1.4388 - accuracy: 0.4873 - val_loss: 1.5285 - val_accuracy: 0.4607\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 16s 396us/sample - loss: 1.3999 - accuracy: 0.5022 - val_loss: 1.5025 - val_accuracy: 0.4715\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 16s 388us/sample - loss: 1.3630 - accuracy: 0.5162 - val_loss: 1.4918 - val_accuracy: 0.4719\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 15s 379us/sample - loss: 1.3330 - accuracy: 0.5246 - val_loss: 1.4855 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 15s 380us/sample - loss: 1.3058 - accuracy: 0.5337 - val_loss: 1.4796 - val_accuracy: 0.4829\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 15s 378us/sample - loss: 1.2802 - accuracy: 0.5442 - val_loss: 1.4512 - val_accuracy: 0.4910\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 1.2477 - accuracy: 0.5570 - val_loss: 1.4685 - val_accuracy: 0.4842\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 1.2284 - accuracy: 0.5637 - val_loss: 1.4620 - val_accuracy: 0.4867\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.2078 - accuracy: 0.5703 - val_loss: 1.4672 - val_accuracy: 0.4902\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.1870 - accuracy: 0.5792 - val_loss: 1.4751 - val_accuracy: 0.4879\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 15s 373us/sample - loss: 1.1648 - accuracy: 0.5864 - val_loss: 1.4635 - val_accuracy: 0.4950\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 15s 374us/sample - loss: 1.1532 - accuracy: 0.5921 - val_loss: 1.4784 - val_accuracy: 0.4880\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.1268 - accuracy: 0.6000 - val_loss: 1.4861 - val_accuracy: 0.4934\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.1084 - accuracy: 0.6039 - val_loss: 1.4845 - val_accuracy: 0.4936\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 15s 377us/sample - loss: 1.0909 - accuracy: 0.6149 - val_loss: 1.4773 - val_accuracy: 0.4957\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 1.0755 - accuracy: 0.6192 - val_loss: 1.4949 - val_accuracy: 0.4969\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 1.0594 - accuracy: 0.6235 - val_loss: 1.4982 - val_accuracy: 0.4985\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.0449 - accuracy: 0.6281 - val_loss: 1.5204 - val_accuracy: 0.4925\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 1.0288 - accuracy: 0.6327 - val_loss: 1.4967 - val_accuracy: 0.4977\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 1.0129 - accuracy: 0.6407 - val_loss: 1.5134 - val_accuracy: 0.5005\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 15s 377us/sample - loss: 0.9977 - accuracy: 0.6433 - val_loss: 1.5179 - val_accuracy: 0.4994\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 15s 376us/sample - loss: 0.9875 - accuracy: 0.6511 - val_loss: 1.5402 - val_accuracy: 0.4975\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 15s 377us/sample - loss: 0.9702 - accuracy: 0.6562 - val_loss: 1.5548 - val_accuracy: 0.4949\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 15s 375us/sample - loss: 0.9547 - accuracy: 0.6605 - val_loss: 1.5540 - val_accuracy: 0.5021\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 0.9481 - accuracy: 0.6637 - val_loss: 1.5757 - val_accuracy: 0.4946\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 16s 392us/sample - loss: 0.9346 - accuracy: 0.6679 - val_loss: 1.5615 - val_accuracy: 0.4954\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 1.4512 - accuracy: 0.4910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4512366218566894, 0.491]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "# test the model\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset everything\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the data for input\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    keras.layers.AlphaDropout(rate=0.2)\n",
    "])\n",
    "\n",
    "# add 20 hidden layers of 100 neuron Dense layers \n",
    "for _ in range(0,20):\n",
    "    model.add(keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "# add the dropout layer\n",
    "model.add(keras.layers.AlphaDropout(rate=0.2))\n",
    "# add our output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(lr=5e-4),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alphadrop_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 493us/sample - loss: 1.9650 - accuracy: 0.2997 - val_loss: 1.8046 - val_accuracy: 0.3535\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.7608 - accuracy: 0.3765 - val_loss: 1.7762 - val_accuracy: 0.3936\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.6817 - accuracy: 0.4079 - val_loss: 1.7729 - val_accuracy: 0.4008\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 15s 385us/sample - loss: 1.6235 - accuracy: 0.4289 - val_loss: 1.6615 - val_accuracy: 0.4321\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 15s 387us/sample - loss: 1.5776 - accuracy: 0.4464 - val_loss: 1.6576 - val_accuracy: 0.4554\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 15s 385us/sample - loss: 1.5393 - accuracy: 0.4638 - val_loss: 1.7310 - val_accuracy: 0.4398\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.5097 - accuracy: 0.4695 - val_loss: 1.7001 - val_accuracy: 0.4468\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 1.4786 - accuracy: 0.4826 - val_loss: 1.7723 - val_accuracy: 0.4590\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 1.4521 - accuracy: 0.4908 - val_loss: 1.6967 - val_accuracy: 0.4556\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.4375 - accuracy: 0.4958 - val_loss: 1.7080 - val_accuracy: 0.4554\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 1.4124 - accuracy: 0.5074 - val_loss: 1.7292 - val_accuracy: 0.4607\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.3893 - accuracy: 0.5164 - val_loss: 1.6552 - val_accuracy: 0.4742\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 1.3669 - accuracy: 0.5199 - val_loss: 1.7507 - val_accuracy: 0.4804\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.3511 - accuracy: 0.5267 - val_loss: 1.7310 - val_accuracy: 0.4719\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 15s 385us/sample - loss: 1.3375 - accuracy: 0.5335 - val_loss: 1.6758 - val_accuracy: 0.4881\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 1.3197 - accuracy: 0.5382 - val_loss: 1.8237 - val_accuracy: 0.4823\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.3076 - accuracy: 0.5439 - val_loss: 1.7818 - val_accuracy: 0.4821\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.2912 - accuracy: 0.5487 - val_loss: 1.8440 - val_accuracy: 0.4764\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 1.2755 - accuracy: 0.5563 - val_loss: 1.7889 - val_accuracy: 0.4918\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.2658 - accuracy: 0.5594 - val_loss: 1.7512 - val_accuracy: 0.4984\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 15s 383us/sample - loss: 1.2582 - accuracy: 0.5607 - val_loss: 1.7728 - val_accuracy: 0.4743\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 15s 382us/sample - loss: 1.2446 - accuracy: 0.5655 - val_loss: 1.7205 - val_accuracy: 0.4873\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 16s 395us/sample - loss: 1.2299 - accuracy: 0.5674 - val_loss: 1.8550 - val_accuracy: 0.4824\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 16s 396us/sample - loss: 1.2237 - accuracy: 0.5749 - val_loss: 1.8778 - val_accuracy: 0.4883\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 16s 390us/sample - loss: 1.2100 - accuracy: 0.5781 - val_loss: 1.8918 - val_accuracy: 0.4895\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 15s 385us/sample - loss: 1.1996 - accuracy: 0.5814 - val_loss: 1.8563 - val_accuracy: 0.5030\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.1857 - accuracy: 0.5867 - val_loss: 1.9367 - val_accuracy: 0.4904\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 16s 388us/sample - loss: 1.1852 - accuracy: 0.5867 - val_loss: 1.8683 - val_accuracy: 0.4933\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 15s 386us/sample - loss: 1.1724 - accuracy: 0.5942 - val_loss: 1.9802 - val_accuracy: 0.4839\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 15s 384us/sample - loss: 1.1721 - accuracy: 0.5930 - val_loss: 1.7127 - val_accuracy: 0.4923\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 1.1578 - accuracy: 0.5982 - val_loss: 1.8376 - val_accuracy: 0.5041\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 1.3089 - accuracy: 0.5689 - val_loss: 1.8532 - val_accuracy: 0.4896\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 4.9350 - accuracy: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.934977342224121, 0.0999]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "# test the model\n",
    "model = keras.models.load_model(\"my_cifar10_alphadrop_model.h5\")\n",
    "model.evaluate(X_test_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 65us/sample - loss: 1.6249 - accuracy: 0.4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6249331756591796, 0.4781]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
